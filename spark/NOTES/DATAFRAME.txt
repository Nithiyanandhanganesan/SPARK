When working with a HiveContext, DataFrames can also be saved as persistent tables using the saveAsTable command. 
Unlike the registerTempTable command, saveAsTable will materialize the contents of the dataframe and create a pointer to the data in the HiveMetastore. 
Persistent tables will still exist even after your Spark program has restarted, as long as you maintain your connection to the same metastore. 
A DataFrame for a persistent table can be created by calling the table method on a SQLContext with the name of the table.

By default saveAsTable will create a “managed table”, meaning that the location of the data will be controlled by the metastore.
Managed tables will also have their data deleted automatically when a table is dropped.